{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dh4LQnJj8KYH"
   },
   "source": [
    "**В этом ноутбуке я провожу оценку производительности ранее обученной модели   \n",
    "(и всей рек.системы в целом) на отложенных оригинальных тестовых данных test_main**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38zGZuRjzu-N"
   },
   "source": [
    "**Какие данные используются**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIH1v2L52jvA"
   },
   "source": [
    "Я не буду делать предсказания на всем test_main, чтобы затем загрузить submission на kaggle.  \n",
    "Я как раньше, разделю **test_main** на 2 равные половины (по хронологии aid в каждой сессии) -   \n",
    "1. на тест.часть **test_history_sessions**\n",
    "2.  на тестовые метки **test_labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Я не буду переобучать модель, полученную на меньшой части от train_main (на train_third_w)  \n",
    "на всем train_main. Это займет много времени, поэтому я попробую получить предсказания на test_main  \n",
    "с помощью обученной ранее модели CatBoost Ranker**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKaZHW1JayYE"
   },
   "source": [
    "В итоге я проверю производительность модели локально на test_labels, а не на тех тестовых метках,  \n",
    "находящихся на LB на Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17673,
     "status": "ok",
     "timestamp": 1699602506424,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "LA8RPA5CyCeq",
    "outputId": "f58dd2d4-3c96-4135-a757-c4a4116f52c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# main_path = '/Users/stanislavkrupnov/Jup.Notebook'\n",
    "\n",
    "main_path = '/content/drive/Othercomputers/Mac/Jup.Notebook'\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "fda2ef49"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "83b980a5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import gc\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from collections import Counter, defaultdict\n",
    "import pyarrow.parquet as pq\n",
    "import shutil\n",
    "import gdown\n",
    "import dask\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJOryrzjFC_R"
   },
   "source": [
    "# Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0PbiB8KFE9X"
   },
   "outputs": [],
   "source": [
    "def metric_eval(predictions: pd.DataFrame, valid: pd.DataFrame,\n",
    "                id2type: dict) -> tuple:\n",
    "    \"\"\"\n",
    "    Вычисляет метрики для оценки качества модели.\n",
    "\n",
    "    Parameters:\n",
    "    - predictions (pd.DataFrame): DataFrame с предсказаниями модели.\n",
    "    - valid (pd.DataFrame): DataFrame с данными для валидации.\n",
    "    - id2type (dict): Словарь для преобразования индексов типов в соответствующие строки.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Кортеж, содержащий локальную метрику и реколл для каждого типа.\n",
    "    \"\"\"\n",
    "    # Преобразование индексов типов в соответствующие строки\n",
    "    valid.type = valid.type.map(lambda idx: id2type[idx])\n",
    "\n",
    "    # Создание списка с метками для каждой сессии и типа\n",
    "    ground_truth = valid.groupby(['session', 'type'])['aid'].apply(list)\n",
    "    ground_truth = ground_truth.reset_index().rename(columns={'aid': 'labels'})\n",
    "\n",
    "    # Обрезка меток для типа 'clicks' до одной метки\n",
    "    ground_truth.loc[ground_truth.type == 'clicks',\n",
    "                     'labels'] = ground_truth.loc[ground_truth.type ==\n",
    "                                                  'clicks', 'labels'].str[:1]\n",
    "\n",
    "    # Объединение предсказаний с истинными метками\n",
    "    submission_with_gt = predictions.merge(\n",
    "        ground_truth[['session', 'type', 'labels']],\n",
    "        how='left',\n",
    "        on=['session', 'type'])\n",
    "\n",
    "    # Отбрасывание сессий без истинных меток\n",
    "    submission_with_gt = submission_with_gt[~submission_with_gt.labels_y.isna(\n",
    "    )]\n",
    "\n",
    "    # Вычисление количества совпадений между предсказанными и истинными метками\n",
    "    submission_with_gt['hits'] = submission_with_gt.apply(\n",
    "        lambda df: len(set(df.labels_x).intersection(set(df.labels_y))),\n",
    "        axis=1)\n",
    "\n",
    "    # Вычисление количества истинных меток для каждого типа\n",
    "    submission_with_gt['gt_count'] = submission_with_gt.labels_y.str.len(\n",
    "    ).clip(0, 20)\n",
    "\n",
    "    # Вычисление реколла для каждого типа\n",
    "    recall_per_type = submission_with_gt.groupby([\n",
    "        'type'\n",
    "    ])['hits'].sum() / submission_with_gt.groupby(['type'])['gt_count'].sum()\n",
    "\n",
    "    # Вычисление локальной метрики на основе реколла для каждого типа\n",
    "    local_validation_score = (recall_per_type * pd.Series({\n",
    "        'clicks': 0.10,\n",
    "        'carts': 0.30,\n",
    "        'orders': 0.60\n",
    "    })).sum()\n",
    "\n",
    "    return local_validation_score, recall_per_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e14e781d"
   },
   "outputs": [],
   "source": [
    "# Функция для чтения данных из кеша\n",
    "def read_file(f):\n",
    "    # Возвращаем DataFrame, соответствующий ключу f в словаре data_cache\n",
    "    return cudf.DataFrame( data_cache[f] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyLTmuK8lVFg"
   },
   "outputs": [],
   "source": [
    "def read_covis_to_dict(name: str, n: int) -> dict:\n",
    "    '''\n",
    "    Считывает данные из нескольких файлов, содержащих матрицу совстречаемости,\n",
    "    и объединяет их в словарь, где ключи - aid_x, значения - списки связанных aid_y.\n",
    "\n",
    "    Параметры:\n",
    "    - name (str): Имя матрицы, используется для формирования пути к файлам.\n",
    "    - n (int): Количество файлов с матрицей.\n",
    "\n",
    "    Возвращает:\n",
    "    - covis_matrix (Dict[str, List[str]]): Словарь, где ключи - aid_x, значения - списки связанных aid_y.\n",
    "    '''\n",
    "    # Инициализация пустого словаря для хранения матрицы совстречаемости\n",
    "    covis_matrix = {}\n",
    "\n",
    "    # Чтение данных из файлов и обновление словаря\n",
    "    for k in tqdm(range(0, n)):\n",
    "        path = f'{main_path}/LB/covis/{name}/{name}_{k}.parquet'\n",
    "\n",
    "        # Первый файл создает словарь, последующие обновляют его\n",
    "        if k == 0:\n",
    "            covis_matrix = pd.read_parquet(path)\n",
    "            covis_matrix = covis_matrix.groupby('aid_x').aid_y.apply(\n",
    "                list).to_dict()\n",
    "        else:\n",
    "            df = pd.read_parquet(path)\n",
    "            df = df.groupby('aid_x').aid_y.apply(list).to_dict()\n",
    "            covis_matrix.update(df)\n",
    "\n",
    "    return covis_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ef47d55"
   },
   "outputs": [],
   "source": [
    "def read_parquet_in_chunks(file_path: str, batch_num: int):\n",
    "    '''\n",
    "    Читает Parquet-файл порциями и возвращает DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): Путь к Parquet-файлу.\n",
    "    - batch_num (int): Количество порций для чтения.\n",
    "\n",
    "    Yields:\n",
    "    - pd.DataFrame: DataFrame, представляющий порцию данных из Parquet-файла.\n",
    "    '''\n",
    "    table = pq.read_table(file_path)\n",
    "    num_rows = len(table)\n",
    "    batch_size = num_rows // batch_num\n",
    "\n",
    "    for i in range(0, num_rows, batch_size):\n",
    "        yield table[i:i + batch_size].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9a6f960"
   },
   "outputs": [],
   "source": [
    "def create_labels(n: int,\n",
    "                  inp_dict: dict,\n",
    "                  covis: dict,\n",
    "                  top_pop_aids: set,\n",
    "                  cov_f: bool,\n",
    "                  b: int = -1) -> dict:\n",
    "    '''\n",
    "    Создает метки для сессий на основе матрицы ко-посещений.\n",
    "\n",
    "    Parameters:\n",
    "    - n (int): Количество кандидатов на сессию.\n",
    "    - inp_dict (dict): Словарь с записями сессий.\n",
    "    - covis (dict): Матрица ко-посещений.\n",
    "    - top_pop_aids (set): Топ популярных товаров.\n",
    "    - cov_f (bool): Создавать ли признак из ковиз-матрицы.\n",
    "    - b (int): Номер файла для сохранения, если cov_f=True.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Словарь с кандидатами.\n",
    "    '''\n",
    "    labels = {}\n",
    "    featuress = {}\n",
    "\n",
    "    for session, aids in tqdm(inp_dict.items()):\n",
    "        # Инициализация словаря для подсчета aids\n",
    "        aid_counter = Counter()\n",
    "\n",
    "        # Цикл по всем aids в сессии\n",
    "        for aid in aids:\n",
    "            # Если aid есть в covis_matrix, увеличиваем его счетчик\n",
    "            if aid in covis:\n",
    "                aid_counter.update(covis[aid])\n",
    "\n",
    "        if len(set(aids)) >= n:  # Оставлю только последние n уникальные aids\n",
    "            labels[session] = list(dict.fromkeys(aids))[-n:]\n",
    "        else:\n",
    "            # Получаем топ встречающихся aids\n",
    "            top_aids = [\n",
    "                aid\n",
    "                for aid, count in aid_counter.most_common(n - len(set(aids)))\n",
    "            ]\n",
    "\n",
    "            # Добавляем исходные aids и топ встречающихся aids в labels\n",
    "            labels[session] = list(set(list(set(aids)) + list(set(top_aids))))\n",
    "\n",
    "            if len(set(aids)) < n:\n",
    "                pops = list(top_pop_aids.difference(set(labels[session])))\n",
    "                labels[session] += pops[:n - len(labels[session])]\n",
    "\n",
    "        if cov_f == False:\n",
    "            continue\n",
    "        else:\n",
    "            # Создание словаря с признаком - рангом (по ко-виз матрице) каждого кандидата внутри сессии\n",
    "            for aid in labels[session]:\n",
    "                if aid in list(aid_counter.keys()):\n",
    "                    if session not in featuress:\n",
    "                        featuress[session] = {}\n",
    "                    featuress[session][aid] = aid_counter[aid]\n",
    "\n",
    "    if cov_f == True:\n",
    "        if b == -1:  # Если мы в функции create_labels\n",
    "            path_ = f'{main_path}/tr/{ver_folder}/featuress.pickle'\n",
    "        else:  # Если мы в функции create_labels_in_batches\n",
    "            path_ = f'{main_path}/tr/{ver_folder}/featuress_{b}.pickle'\n",
    "\n",
    "        with open(path_, 'wb') as file:\n",
    "            pickle.dump(featuress, file)\n",
    "\n",
    "        print(\n",
    "            f'Словарь с признаком-рангом по ковиз-матрице сохранен в : {path_}'\n",
    "        )\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b016ac9"
   },
   "outputs": [],
   "source": [
    "def create_labels_in_batches(k: int, n: int, inp_dict: dict, covis: dict,\n",
    "                             top_pop_aids: set, cov_f: bool) -> dict:\n",
    "    '''\n",
    "    Создает метки для сессий на основе матрицы ко-посещений по батчам.\n",
    "\n",
    "    Parameters:\n",
    "    - k (int): Количество батчей.\n",
    "    - n (int): Количество кандидатов на сессию.\n",
    "    - inp_dict (dict): Словарь с записями сессий.\n",
    "    - covis (dict): Матрица ко-посещений.\n",
    "    - top_pop_aids (set): Топ популярных товаров.\n",
    "    - cov_f (bool): Создавать ли признак из ковиз-матрицы.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Словарь с кандидатами.\n",
    "    '''\n",
    "    labels = {}\n",
    "    partt = len(inp_dict) // k\n",
    "\n",
    "    for batch in tqdm(range(k), desc='part'):\n",
    "\n",
    "        start = partt * batch\n",
    "        end = partt * (batch + 1)\n",
    "        slicee_ = list(inp_dict.items())[start:end]\n",
    "        slicee = dict(slicee_)\n",
    "\n",
    "        labels_ = create_labels(n=n,\n",
    "                                inp_dict=slicee,\n",
    "                                covis=covis,\n",
    "                                top_pop_aids=top_pop_aids,\n",
    "                                cov_f=cov_f,\n",
    "                                b=batch)\n",
    "        labels.update(labels_)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9a484e0"
   },
   "outputs": [],
   "source": [
    "def create_pop_features(for_features_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Создает признак ранжирования aid по встречаемости в группах по типам.\n",
    "\n",
    "    Parameters:\n",
    "    - for_features_df (pd.DataFrame): Датасет с данными для признака.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Датасет с признаком.\n",
    "    '''\n",
    "    # Создадим пустой DataFrame, в который будем записывать результаты\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    # Сгруппируем исходный DataFrame по столбцу 'type'\n",
    "    grouped = for_features_df.groupby('type')\n",
    "\n",
    "    id_2_type = {0: 'clicks', 1: 'carts', 2: 'orders'}\n",
    "\n",
    "    # Пройдемся по каждой группе и выполним ранжирование aid по встречаемости\n",
    "    for name, group in tqdm(grouped):\n",
    "        # Считаем количество вхождений каждого aid в текущей группе и создадим временный DataFrame\n",
    "        aid_counts = group['aid'].value_counts().reset_index()\n",
    "        aid_counts.columns = ['aid', 'count']\n",
    "\n",
    "        # Добавим столбец с рангом, используя функцию rank()\n",
    "        aid_counts['rank'] = aid_counts['count'].rank(ascending=False,\n",
    "                                                      method='dense')\n",
    "        aid_counts.drop(columns=['count'], inplace=True)\n",
    "\n",
    "        # Присоединим результат к исходной группе и добавим в общий результатный DataFrame\n",
    "        merged_group = pd.merge(group, aid_counts, on='aid', how='left')\n",
    "\n",
    "        # Создадим имена для столбцов рангов на основе типа 'type'\n",
    "        rank_column_name = 'rank_' + id_2_type[name]\n",
    "        merged_group.rename(columns={'rank': rank_column_name}, inplace=True)\n",
    "\n",
    "        result_df = pd.concat([result_df, merged_group], ignore_index=True)\n",
    "\n",
    "        result_df.fillna(-1, inplace=True)\n",
    "        result_df.rank_clicks = result_df.rank_clicks.astype(np.int32)\n",
    "        result_df.rank_carts = result_df.rank_carts.astype(np.int32)\n",
    "        result_df.rank_orders = result_df.rank_orders.astype(np.int32)\n",
    "        result_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e772eecc"
   },
   "outputs": [],
   "source": [
    "def add_targets(dataframe_: pd.DataFrame, targets: pd.DataFrame,\n",
    "                targ_type: int) -> pd.DataFrame:\n",
    "    '''\n",
    "    Добавляет таргеты к датафрейму.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe_ (pd.DataFrame): Датафрейм, которому нужны таргеты.\n",
    "    - targets (pd.DataFrame): Датафрейм с таргетами всех типов.\n",
    "    - targ_type (int): Текущий тип таргета.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Датафрейм с нужными таргетами.\n",
    "    '''\n",
    "    targets_ = targets.loc[targets['type'] == targ_type,\n",
    "                           ['session', 'aid', 'type']].rename(columns={\n",
    "                               'type': 'target'\n",
    "                           }).copy()\n",
    "    targets_['target'] = 1\n",
    "    targets_ = targets_.drop_duplicates()\n",
    "    merge_cols = [\"session\", \"aid\"]\n",
    "    dataframe = dataframe_.merge(targets_, on=merge_cols, how=\"left\")\n",
    "    dataframe = dataframe.fillna(0)\n",
    "    dataframe.target = dataframe.target.astype(np.uint8)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50ff94f9"
   },
   "outputs": [],
   "source": [
    "def w_pbar(pbar: tqdm, func: callable):\n",
    "    '''\n",
    "    Оборачивает функцию, обновляя tqdm прогресс бар.\n",
    "\n",
    "    Parameters:\n",
    "    - pbar (tqdm): Прогресс бар.\n",
    "    - func (callable): Функция.\n",
    "\n",
    "    Returns:\n",
    "    - callable: Обернутая функция.\n",
    "    '''\n",
    "    def foo(*args, **kwargs):\n",
    "        pbar.update(1)\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41wakUc0WxbO"
   },
   "outputs": [],
   "source": [
    "def read_parquets(path: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    Считывает данные из нескольких файлов формата Parquet, находящихся в заданной директории,\n",
    "    и объединяет их в один DataFrame.\n",
    "\n",
    "    Параметры:\n",
    "    - path (str): Путь к файлам формата Parquet.\n",
    "\n",
    "    Возвращает:\n",
    "    - tr_candidates (pd.DataFrame): Объединенный DataFrame, содержащий данные из файлов Parquet.\n",
    "    '''\n",
    "    # Получение списка файлов Parquet в указанной директории\n",
    "    file_list = glob.glob(path)\n",
    "\n",
    "    # Инициализация пустого DataFrame для сбора данных\n",
    "    tr_candidates = pd.DataFrame()\n",
    "\n",
    "    # Цикл для чтения и объединения файлов\n",
    "    for file in tqdm(file_list):\n",
    "        # Чтение файла Parquet во временный DataFrame\n",
    "        df_ = pd.read_parquet(file)\n",
    "\n",
    "        # Объединение временного DataFrame с основным датасетом\n",
    "        tr_candidates = pd.concat([tr_candidates, df_], ignore_index=True)\n",
    "\n",
    "    return tr_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrOTgvRyblfW"
   },
   "source": [
    "# Разбиение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2SWU0t2fYZJ"
   },
   "outputs": [],
   "source": [
    "test_main = pd.read_parquet(f'{main_path}/main_dataframes/test_main.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRUdUWIxqhUo"
   },
   "outputs": [],
   "source": [
    "def split_df_into_halves(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Разделить датафрейм на две части для каждой сессии, основываясь на столбце 'ts'\n",
    "    внутри каждой сессии.\n",
    "\n",
    "    Параметры:\n",
    "        df: Входной датафрейм с колонками 'session', 'aid' и 'ts'.\n",
    "\n",
    "    Возвращает:\n",
    "        tuple: Кортеж, содержащий два датафрейма. Первый датафрейм содержит\n",
    "        первую половину 'aid' для каждой сессии, а второй датафрейм содержит вторую\n",
    "        половину 'aid' для каждой сессии.\n",
    "    \"\"\"\n",
    "    # Сортировка входного датафрейма по столбцу 'ts' внутри каждой сессии\n",
    "    df.sort_values(by=['session', 'ts'], inplace=True)\n",
    "\n",
    "    # Разделение датафрейма на две половины (первую и вторую половины 'aid')\n",
    "    half_size = df.groupby('session')['aid'].transform('size') // 2\n",
    "    first_half_df = df[\n",
    "        df.groupby('session').cumcount() < half_size].reset_index(drop=True)\n",
    "    second_half_df = df[\n",
    "        df.groupby('session').cumcount() >= half_size].reset_index(drop=True)\n",
    "\n",
    "    return first_half_df, second_half_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KB_RBipqb4TH"
   },
   "outputs": [],
   "source": [
    "test_candidates_sessions, test_labels = split_df_into_halves(test_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9x-9n57rhcO"
   },
   "outputs": [],
   "source": [
    "folder_path = f'{main_path}/LB/data'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "#  Сохраняю для дальнейшего использования\n",
    "test_labels.to_parquet(f'{main_path}/LB/data/test_labels.parquet')\n",
    "test_candidates_sessions.to_parquet(\n",
    "    f'{main_path}/LB/data/test_candidates_sessions.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jP4-xC3Br_xy"
   },
   "source": [
    "**Разбиение на батчи для создания co-vis matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f45aa55c"
   },
   "outputs": [],
   "source": [
    "folder_path = 'test_candidates_sessions_b'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "dask_df = dd.from_pandas(test_candidates_sessions, npartitions=2)\n",
    "dask_df.repartition(20).to_parquet(f'{folder_path}/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNT7IDdYLtSH"
   },
   "source": [
    "# Co-vis матрицы создание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PP6wH5sCus-f"
   },
   "outputs": [],
   "source": [
    "matrix_name = 'test_covis_matrix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1699327425616,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "J7EAKKsg1xHv",
    "outputId": "ad1d9545-234d-4c42-a213-b4490216e60c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'rapidsai-csp-utils' already exists and is not an empty directory.\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/rapidsai-csp-utils/colab/pip-install.py\", line 28, in <module>\n",
      "    if ('K80' not in gpu_name):\n",
      "TypeError: a bytes-like object is required, not 'str'\n"
     ]
    }
   ],
   "source": [
    "# Чтобы работало - запускаю ячейку, затем перезагружаю сеанс(не отключаюсь), и еще раз\n",
    "# - все робит!\n",
    "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
    "!python rapidsai-csp-utils/colab/pip-install.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4AhABbJS0OmD"
   },
   "outputs": [],
   "source": [
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TElamb7n1ujn"
   },
   "outputs": [],
   "source": [
    "data_cache = {} # Кеш данных CPU\n",
    "type_labels = {'clicks':0, 'carts':1, 'orders':2} # Словарь меток типов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYGyA2vW1xEn"
   },
   "outputs": [],
   "source": [
    "# Считывание и кеширование данных\n",
    "files = glob.glob(f'test_candidates_sessions_b/*') # Получаем список файлов\n",
    "for f in files: data_cache[f] = pd.read_parquet(f) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgrtjzV26IcU"
   },
   "outputs": [],
   "source": [
    "READ_CT = 5\n",
    "CHUNK = int( np.ceil( len(files)/6 )) # Размер каждого chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1699327443061,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "ud-gj-YHhchh",
    "outputId": "d7eb941a-ce1f-4052-946d-8e36db03ce4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x7dc40e578b30 to Device at 0x7dc40e56dcf0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24135,
     "status": "ok",
     "timestamp": 1699178946098,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "SdhivL64hdIg",
    "outputId": "114b94e2-83d5-4743-8ce0-7a35c92aa55a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### DISK PART 1\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 2\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 3\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 4\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 5\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 6\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 7\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 8\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 9\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 10\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 11\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 12\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 13\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 14\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 15\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 16\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 17\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 18\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 19\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "\n",
      "### DISK PART 20\n",
      "Processing files 0 thru 3 in groups of 5...\n",
      "0 , \n",
      "Processing files 4 thru 7 in groups of 5...\n",
      "4 , \n",
      "Processing files 8 thru 11 in groups of 5...\n",
      "8 , \n",
      "Processing files 12 thru 15 in groups of 5...\n",
      "12 , \n",
      "Processing files 16 thru 19 in groups of 5...\n",
      "16 , \n",
      "Processing files 20 thru 19 in groups of 5...\n",
      "\n",
      "CPU times: user 21.3 s, sys: 2.45 s, total: 23.7 s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Создание директории для сохранения файлов\n",
    "folder_path = f'{matrix_name}'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Веса для каждого типа события\n",
    "type_weight = {0: 1, 1: 6, 2: 3}\n",
    "\n",
    "# Количество частей для разделения данных (оптимизация использования памяти)\n",
    "disk_pieces = 20\n",
    "\n",
    "# Размер каждой части данных\n",
    "size = 1.86e6 / disk_pieces\n",
    "\n",
    "# Вычисление частями для управления памятью\n",
    "for part in range(disk_pieces):\n",
    "    print()\n",
    "    print('### ЧАСТЬ НА ДИСКЕ', part + 1)\n",
    "\n",
    "    # Слияние - самый быстрый процесс слияния частей внутри частей\n",
    "    # => Внешние части\n",
    "    for j in range(6):\n",
    "        a = j * CHUNK\n",
    "        b = min((j + 1) * CHUNK, len(files))\n",
    "        print(f'Обработка файлов с {a} по {b-1} в группах по {READ_CT}...')\n",
    "\n",
    "        tmp2 = None\n",
    "        df = None\n",
    "\n",
    "        # => Внутренние части\n",
    "        for k in range(a, b, READ_CT):\n",
    "            # Чтение файла\n",
    "            df = [read_file(files[k])]\n",
    "            for i in range(1, READ_CT):\n",
    "                if k + i < b:\n",
    "                    df.append(read_file(files[k+i]))\n",
    "            df = cudf.concat(df, ignore_index=True, axis=0)\n",
    "            df = df.sort_values(['session', 'ts'], ascending=[True, False])\n",
    "\n",
    "            # Использование хвоста сессии\n",
    "            df = df.reset_index(drop=True)\n",
    "            df['n'] = df.groupby('session').cumcount()\n",
    "            df = df.loc[df.n < 70].drop('n', axis=1)\n",
    "\n",
    "            # Создание пар\n",
    "            df = df.merge(df, on='session')\n",
    "            df = df.loc[((df.ts_x - df.ts_y).abs() < 24 * 60 * 60) & (df.aid_x != df.aid_y)]\n",
    "\n",
    "            # Управление памятью - вычисление частями\n",
    "            df = df.loc[(df.aid_x >= part * size) & (df.aid_x < (part + 1) * size)]\n",
    "\n",
    "            # Назначение весов\n",
    "            # Применяет веса к типам событий и суммирует веса для каждой пары 'aid'.\n",
    "            df = df[['session', 'aid_x', 'aid_y', 'type_y']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "            df['wgt'] = df.type_y.map(type_weight)\n",
    "            df = df[['aid_x', 'aid_y', 'wgt']]\n",
    "            df.wgt = df.wgt.astype('float32')\n",
    "            df = df.groupby(['aid_x', 'aid_y']).wgt.sum()\n",
    "\n",
    "            # Сочетание внутренних частей\n",
    "            if k == a:\n",
    "               tmp2 = df\n",
    "            else:\n",
    "               tmp2 = tmp2.add(df, fill_value=0)\n",
    "            print(k, ', ', end='')\n",
    "        print()\n",
    "\n",
    "        # Сочетание внешних частей\n",
    "        if a == 0:\n",
    "          tmp = tmp2\n",
    "        else:\n",
    "          tmp = tmp.add(tmp2, fill_value=0)\n",
    "        del tmp2, df\n",
    "        gc.collect()\n",
    "\n",
    "    # Преобразование матрицы в словарь\n",
    "    tmp = tmp.reset_index()\n",
    "    tmp = tmp.sort_values(['aid_x', 'wgt'], ascending=[True, False])\n",
    "\n",
    "    # Сохранение топ-50\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    tmp['n'] = tmp.groupby('aid_x').aid_y.cumcount()\n",
    "    tmp = tmp.loc[tmp.n < 50].drop('n', axis=1)\n",
    "\n",
    "    # Сохранение части на диск (конвертация в pandas сначала использует меньше памяти)\n",
    "    tmp.to_pandas().to_parquet(f'{matrix_name}/{matrix_name}_{PART}.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1699178962646,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "lvoLBo1ur2jG",
    "outputId": "57a7cc10-1eea-454e-9538-9dc74cd02669"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_5.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_4.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_2.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_3.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_12.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_18.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_13.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_9.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_6.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_10.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_0.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_16.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_19.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_14.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_11.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_1.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_7.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_15.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_17.parquet',\n",
       " '/content/drive/Othercomputers/Mac/Jup.Notebook/LB/covis/test_covis_matrix/test_covis_matrix_8.parquet']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = f'{main_path}/LB/covis/{matrix_name}'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "file_list = glob.glob(f'{matrix_name}/*')\n",
    "[shutil.copy(file, f'{main_path}/LB/covis/{matrix_name}/') for file in file_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbNQVXb8hFmv"
   },
   "source": [
    "# Создание признаков test_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BmjoVX28uy7J"
   },
   "outputs": [],
   "source": [
    "test_candidates_sessions = pd.read_parquet(\n",
    "    f'{main_path}/LB/data/test_candidates_sessions.parquet')\n",
    "train_main = pd.read_parquet(f'{main_path}/main_dataframes/train_main.parquet')\n",
    "\n",
    "# Данные для item признаков\n",
    "for_features_df_items = pd.concat([test_candidates_sessions, train_main])\n",
    "for_features_df_items.sort_values(by='session', inplace=True)\n",
    "for_features_df_items['ts'] = pd.to_datetime(for_features_df_items['ts'],\n",
    "                                             unit='s')\n",
    "\n",
    "# Данные для session, session-item признаков\n",
    "for_features_df_sessions = test_candidates_sessions\n",
    "for_features_df_sessions.sort_values(by='session', inplace=True)\n",
    "for_features_df_sessions['ts'] = pd.to_datetime(for_features_df_sessions['ts'],\n",
    "                                                unit='s')\n",
    "\n",
    "del test_candidates_sessions, train_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byWGAeb7-1st"
   },
   "source": [
    "## Признаки товаров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1K1ouJ0_hO7"
   },
   "source": [
    "**База 6 признаков**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGTasqNr_Oxf"
   },
   "outputs": [],
   "source": [
    "lv_item_features = for_features_df_items.groupby('aid').agg({\n",
    "    'aid': 'count',\n",
    "    'session': 'nunique',\n",
    "    'type': 'mean'\n",
    "})\n",
    "lv_item_features.columns = [\n",
    "    'item_quantity_in_df', 'sessions_w_item', 'mean_item_type'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7OSNquB-4qr"
   },
   "outputs": [],
   "source": [
    "lv_item_features.item_quantity_in_df = lv_item_features.item_quantity_in_df.astype(\n",
    "    np.int32)\n",
    "lv_item_features.sessions_w_item = lv_item_features.sessions_w_item.astype(\n",
    "    np.int32)\n",
    "lv_item_features.mean_item_type = lv_item_features.mean_item_type.astype(\n",
    "    np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCfZXDvF_QZt"
   },
   "outputs": [],
   "source": [
    "lv_item_features.reset_index(inplace = True)\n",
    "lv_item_features.aid = lv_item_features.aid.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8a0dp7h_Sw-"
   },
   "outputs": [],
   "source": [
    "lv_item_features.to_parquet(\n",
    "    f'{main_path}/LB/features/test/base_item_features.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLjlg4F-mSLm"
   },
   "source": [
    "### Доп признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNYkCCyO8ao0"
   },
   "outputs": [],
   "source": [
    "for_features_df = pl.DataFrame({\n",
    "    'session':\n",
    "    pl.Series(for_features_df_items['session']),\n",
    "    'aid':\n",
    "    pl.Series(for_features_df_items['aid']),\n",
    "    'type':\n",
    "    pl.Series(for_features_df_items['type']),\n",
    "    'ts':\n",
    "    pl.Series(for_features_df_items['ts'])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCb4RNKIAw1G"
   },
   "outputs": [],
   "source": [
    "def get_time_diff(group) -> dict:\n",
    "    '''\n",
    "    Вычисляет временные разницы между различными типами событий в группе.\n",
    "\n",
    "    Parameters:\n",
    "    - group (DataFrame): Группа данных.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Словарь с временными разницами.\n",
    "    '''\n",
    "    # Получаем минимальные временные метки для каждого типа события\n",
    "    click_ts_min = group.filter(pl.col('type') == 0).select('ts').min().item()\n",
    "    cart_ts_min = group.filter(pl.col('type') == 1).select('ts').min().item()\n",
    "    ord_ts_min = group.filter(pl.col('type') == 2).select('ts').min().item()\n",
    "\n",
    "    # Вычисляем временные разницы и преобразуем их в секунды\n",
    "    if click_ts_min is not None and cart_ts_min is not None and \\\n",
    "            click_ts_min <= cart_ts_min:\n",
    "        click_to_cart_t = int((cart_ts_min - click_ts_min).total_seconds())\n",
    "    else:\n",
    "        click_to_cart_t = -1\n",
    "\n",
    "    if click_ts_min is not None and ord_ts_min is not None and \\\n",
    "            click_ts_min <= ord_ts_min:\n",
    "        click_to_ord_t = int((ord_ts_min - click_ts_min).total_seconds())\n",
    "    else:\n",
    "        click_to_ord_t = -1\n",
    "\n",
    "    # Возвращаем результат в виде словаря\n",
    "    return {\n",
    "        'aid': group['aid'][0],\n",
    "        'cl_to_crt_med_time': click_to_cart_t,\n",
    "        'cl_to_ord_med_time': click_to_ord_t\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqU0lOtDA0Lz"
   },
   "outputs": [],
   "source": [
    "def most_active_time_(group) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "        Определяет активное время на основе столбца 'ts' в группе данных.\n",
    "\n",
    "        :params group: DataFrame с данными.\n",
    "        :return (pl.DataFrame): Значение времени.\n",
    "        \"\"\"\n",
    "    group = group.with_columns(pl.col('ts').dt.hour())\n",
    "\n",
    "    def get_daytime(ts_value):\n",
    "        if (ts_value >= 23) & (ts_value < 4):\n",
    "            return 0  #ночь\n",
    "        elif (ts_value >= 4) & (ts_value < 11):\n",
    "            return 1  #утро\n",
    "        elif (ts_value >= 11) & (ts_value < 15):\n",
    "            return 2  #день\n",
    "        else:\n",
    "            return 3  #вечер\n",
    "\n",
    "    most_active_t = group.with_columns(\n",
    "        pl.col('ts').apply(get_daytime).alias('daytime'))\n",
    "    most_active_t = most_active_t.with_columns(\n",
    "        pl.median('daytime').alias('most_active_time').cast(pl.Int8))\n",
    "\n",
    "    return most_active_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uau8s08A8Pr"
   },
   "outputs": [],
   "source": [
    "def create_features(group: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Создает признаки на основе различий во времени и активности пользователя\n",
    "    для заданной группы данных.\n",
    "\n",
    "    Параметры:\n",
    "    - group: pandas.DataFrame\n",
    "        Входной DataFrame, содержащий сессии пользователей и их взаимодействия.\n",
    "\n",
    "    Возвращает:\n",
    "    - pl.DataFrame\n",
    "        DataFrame с уникальными значениями aid, включая медианные времена перехода\n",
    "        от \"click\" к \"cart\" и от \"click\" к \"order\", а также самое активное время суток.\n",
    "    \"\"\"\n",
    "\n",
    "    # Вычисление медианных времен для перехода от \"click\" к \"cart\" для каждой сессии.\n",
    "    click_to_cart_times = (group.groupby('session').agg(\n",
    "        **get_time_diff(group)).median().select(\n",
    "            [pl.col('aid').cast(pl.Int32),\n",
    "             pl.col('cl_to_crt_med_time')]))\n",
    "\n",
    "    # Вычисление медианных времен для перехода от \"click\" к \"order\" для каждой сессии.\n",
    "    click_to_ord_times = (group.groupby('session').agg(\n",
    "        **get_time_diff(group)).median().select(\n",
    "            [pl.col('aid').cast(pl.Int32),\n",
    "             pl.col('cl_to_ord_med_time')]))\n",
    "\n",
    "    # Вычисление времени суток наибольшей активности для каждого aid.\n",
    "    most_active_time = most_active_time_(group) \\\n",
    "                        .select([pl.col('aid').cast(pl.Int32),\n",
    "                                 pl.col('most_active_time')])\n",
    "\n",
    "    # Создание DataFrame с уникальными aid, включающий медианные времена\n",
    "    # и время суток наибольшей активности.\n",
    "    return (\n",
    "        group.select('aid').unique().join(\n",
    "            click_to_cart_times, on='aid')  # Медианное время в секундах,\n",
    "        # спустя которое пользователи переходят от \"click\" к \"cart\"  для данного aid.\n",
    "        .join(click_to_ord_times, on='aid')  # Медианное время в секундах,\n",
    "        # спустя которое пользователи переходят от \"click\" к \"order\" для данного aid.\n",
    "        .join(most_active_time, on='aid')  # Время суток, в которые наиболее\n",
    "        # активно взаимодействуют с этим aid.\n",
    "        .unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4432387,
     "status": "ok",
     "timestamp": 1699285759665,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "EgOyH7vm8ao1",
    "outputId": "e20aae25-d322-4f8d-dff1-24ccfb5dec83",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1855603/1855603 [2:23:04<00:00, 216.17it/s]\n"
     ]
    }
   ],
   "source": [
    "num_groups = len(for_features_df_items[\"aid\"].unique().to_list())\n",
    "\n",
    "with tqdm(total=num_groups) as pbar:\n",
    "    dop_item_features = (for_features_df.groupby('aid').apply(\n",
    "        w_pbar(pbar, create_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1KOKgt9YBHA_"
   },
   "outputs": [],
   "source": [
    "# Вычисление дополнительных признаков\n",
    "first_aids = for_features_df.groupby('session').apply(lambda x: x.filter(\n",
    "    pl.col('ts') == x.select('ts').min()).select(['session', 'aid']))\n",
    "print(1)\n",
    "\n",
    "last_aids = for_features_df.groupby('session').apply(lambda x: x.filter(\n",
    "    pl.col('ts') == x.select('ts').max()).select(['session', 'aid']))\n",
    "print(2)\n",
    "\n",
    "aid_posit_percents = (for_features_df.join(first_aids, on='session').rename({\n",
    "    'aid_right':\n",
    "    'first_aid'\n",
    "}).join(last_aids, on='session').rename({'aid_right': 'last_aid'}))\n",
    "print(3)\n",
    "aid_posit_percents = aid_posit_percents.drop(['ts', 'type']).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItJGkdF8BIvn"
   },
   "outputs": [],
   "source": [
    "def aid_percents(group: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Рассчитывает процент сессий, в которых 'aid' является первым и последним aid.\n",
    "\n",
    "    Параметры:\n",
    "    - group (pl.DataFrame): Группа данных.\n",
    "\n",
    "    Возвращает:\n",
    "    - pl.DataFrame: DataFrame, содержащий 'aid', процент первого aid и процент последнего aid.\n",
    "    \"\"\"\n",
    "    # Рассчитываем процент сессий, в которых 'aid' является первым aid\n",
    "    first_aid_p = (\n",
    "        group.filter(pl.col('aid') == pl.col('first_aid')).select(pl.count()) /\n",
    "        group.select(pl.col('session').unique().count())).item()\n",
    "\n",
    "    # Рассчитываем процент сессий, в которых 'aid' является последним aid\n",
    "    last_aid_p = (\n",
    "        group.filter(pl.col('aid') == pl.col('last_aid')).select(pl.count()) /\n",
    "        group.select(pl.col('session').unique().count())).item()\n",
    "\n",
    "    # Создаем DataFrame с 'aid', процентом первого aid и процентом последнего aid\n",
    "    result_df = pl.DataFrame({\n",
    "        'aid': group['aid'][0],\n",
    "        'first_aid_percent': first_aid_p,\n",
    "        'last_aid_percent': last_aid_p\n",
    "    })\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUv2rY_78ao2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Вычисление доп признаков 'first_aid_percent', 'last_aid_percent'\n",
    "num_groups = aid_posit_percents.get_column(\"aid\").unique().len()\n",
    "\n",
    "with tqdm(total=num_groups) as pbar:\n",
    "    aid_posit_percents = aid_posit_percents \\\n",
    "                        .groupby('aid') \\\n",
    "                        .apply(w_pbar(pbar,aid_percents))\n",
    "\n",
    "aid_posit_percents = aid_posit_percents.with_columns(\n",
    "    pl.col('aid').cast(pl.Int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9yvr2cxR8ao2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dop_item_features = dop_item_features.join(aid_posit_percents, on = 'aid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_R5jit948ao2"
   },
   "outputs": [],
   "source": [
    "dop_item_features.write_parquet(\n",
    "    file=f'{main_path}/lv/ver_6/dop_item_features.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWg0qCiG-nuZ"
   },
   "source": [
    "## Признаки сессий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrpLjsP-_kqk"
   },
   "source": [
    "**База 6 признаков**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzF2KG1D-lTO"
   },
   "outputs": [],
   "source": [
    "lv_user_features = for_features_df_sessions.groupby('session').agg({\n",
    "    'session':\n",
    "    'count',\n",
    "    'aid':\n",
    "    'nunique',\n",
    "    'type':\n",
    "    'mean'\n",
    "})\n",
    "lv_user_features.columns = [\n",
    "    'session_quantity_in_df', 'items_in_session', 'mean_session_type'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Fz2bKrl_VzS"
   },
   "outputs": [],
   "source": [
    "lv_user_features.session_quantity_in_df = lv_user_features.session_quantity_in_df.astype(\n",
    "    np.int32)\n",
    "lv_user_features.items_in_session = lv_user_features.items_in_session.astype(\n",
    "    np.int32)\n",
    "lv_user_features.mean_session_type = lv_user_features.mean_session_type.astype(\n",
    "    np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BoXp9VSk_Xvt"
   },
   "outputs": [],
   "source": [
    "lv_user_features.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8tBX3CE_ZcE"
   },
   "outputs": [],
   "source": [
    "lv_user_features.session = lv_user_features.session.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SD3MJ3gw_bA7"
   },
   "outputs": [],
   "source": [
    "lv_user_features.to_parquet(\n",
    "    f'{main_path}/LB/features/test/base_user_features.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QkJH4Y4JSnuO"
   },
   "source": [
    "### Доп признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1274,
     "status": "ok",
     "timestamp": 1699523738843,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "bPFcLeVsZNL4",
    "outputId": "b2ff674f-bf47-4918-af3f-9767a88a8bcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'rapidsai-csp-utils' already exists and is not an empty directory.\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/rapidsai-csp-utils/colab/pip-install.py\", line 28, in <module>\n",
      "    if ('K80' not in gpu_name):\n",
      "TypeError: a bytes-like object is required, not 'str'\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
    "!python rapidsai-csp-utils/colab/pip-install.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxs3zgekZNL5"
   },
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1699523742519,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "rzvFOFAfZNL6",
    "outputId": "83444023-57f7-4376-9ae4-154989fe4c32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x7c2f6dacc0e0 to Device at 0x7c2f6dcb9c00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "cuda.select_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtEW7QZFZGAX"
   },
   "outputs": [],
   "source": [
    "cu_for_features_df = cudf.DataFrame(for_features_df_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vugTFl_Zqhf"
   },
   "outputs": [],
   "source": [
    "chunk_size = 500000\n",
    "\n",
    "chunks = [\n",
    "    cu_for_features_df[i:i + chunk_size]\n",
    "    for i in range(0, len(cu_for_features_df), chunk_size)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 636432,
     "status": "ok",
     "timestamp": 1699455714887,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "uG4BopKmSqLe",
    "outputId": "40353625-3d4c-4e4e-889f-80afa09066aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/cudf/core/groupby/groupby.py:1273: RuntimeWarning: GroupBy.apply() performance scales poorly with number of groups. Got 146086 groups. Some functions may perform better by passing engine='jit'\n",
      "  warnings.warn(\n",
      " 17%|█▋        | 1/6 [01:39<08:17, 99.58s/it]/usr/local/lib/python3.10/dist-packages/cudf/core/groupby/groupby.py:1273: RuntimeWarning: GroupBy.apply() performance scales poorly with number of groups. Got 155896 groups. Some functions may perform better by passing engine='jit'\n",
      "  warnings.warn(\n",
      " 33%|███▎      | 2/6 [03:27<06:58, 104.58s/it]/usr/local/lib/python3.10/dist-packages/cudf/core/groupby/groupby.py:1273: RuntimeWarning: GroupBy.apply() performance scales poorly with number of groups. Got 155898 groups. Some functions may perform better by passing engine='jit'\n",
      "  warnings.warn(\n",
      " 50%|█████     | 3/6 [05:16<05:19, 106.54s/it]/usr/local/lib/python3.10/dist-packages/cudf/core/groupby/groupby.py:1273: RuntimeWarning: GroupBy.apply() performance scales poorly with number of groups. Got 159965 groups. Some functions may perform better by passing engine='jit'\n",
      "  warnings.warn(\n",
      " 67%|██████▋   | 4/6 [07:05<03:35, 107.58s/it]/usr/local/lib/python3.10/dist-packages/cudf/core/groupby/groupby.py:1273: RuntimeWarning: GroupBy.apply() performance scales poorly with number of groups. Got 163161 groups. Some functions may perform better by passing engine='jit'\n",
      "  warnings.warn(\n",
      " 83%|████████▎ | 5/6 [08:59<01:49, 109.82s/it]/usr/local/lib/python3.10/dist-packages/cudf/core/groupby/groupby.py:1273: RuntimeWarning: GroupBy.apply() performance scales poorly with number of groups. Got 140702 groups. Some functions may perform better by passing engine='jit'\n",
      "  warnings.warn(\n",
      "100%|██████████| 6/6 [10:35<00:00, 105.99s/it]\n"
     ]
    }
   ],
   "source": [
    "# Определите структуру и названия столбцов для итогового DataFrame\n",
    "columns = [\n",
    "    'session', 'session_len', 'last_aid_type_0', 'last_aid_type_1',\n",
    "    'last_aid_type_2', 'mn_time_b/w_aids', 'freq_per_clicks', 'freq_per_carts',\n",
    "    'freq_per_orders', 'type_counts_clicks', 'type_counts_carts',\n",
    "    'type_counts_orders', 'ratio_ses_clicks', 'ratio_ses_carts',\n",
    "    'ratio_ses_orders', 'ses_aid_duplic_rate'\n",
    "]\n",
    "\n",
    "# Создайте итоговый DataFrame с пустой структурой\n",
    "dop_ses_fts_df = cudf.DataFrame(columns=columns)\n",
    "\n",
    "for chunk in tqdm(chunks):\n",
    "\n",
    "    chunk = chunk.sort_values(by='session')\n",
    "    # Создание признака 'session_len' (длина каждой сессии в минутах)\n",
    "    session_lengths = round((chunk.groupby('session')['ts'].apply(lambda x: (\n",
    "        x.max() - x.min())).astype('timedelta64[s]').astype('int64') / 60), 0)\n",
    "    chunk['session_len'] = chunk['session'].map(session_lengths).astype(\n",
    "        np.int32)\n",
    "\n",
    "    # Создание признака 'last_aid_type' (последнее действие каждого типа в каждой сесси\n",
    "    last_aid_type_0 = chunk[chunk['type'] == 0].groupby(\n",
    "        ['session'])['aid'].transform('last')\n",
    "    chunk['last_aid_type_0'] = last_aid_type_0\n",
    "    chunk['last_aid_type_0'] = chunk['last_aid_type_0'].fillna(0)\n",
    "    last_aid_type_1 = chunk[chunk['type'] == 1].groupby(\n",
    "        ['session'])['aid'].transform('last')\n",
    "    chunk['last_aid_type_1'] = last_aid_type_1\n",
    "    chunk['last_aid_type_1'] = chunk['last_aid_type_1'].fillna(0)\n",
    "    last_aid_type_2 = chunk[chunk['type'] == 2].groupby(\n",
    "        ['session'])['aid'].transform('last')\n",
    "    chunk['last_aid_type_2'] = last_aid_type_2\n",
    "    chunk['last_aid_type_2'] = chunk['last_aid_type_2'].fillna(0)\n",
    "\n",
    "    # 'mn_time_b/w_aids' Среднее время между действиями в сессии\n",
    "    dfff = chunk.to_pandas()\n",
    "    dfff = dfff.sort_values(['session', 'ts'])\n",
    "    dfff['time_diff'] = dfff.groupby('session')['ts'].diff()\n",
    "    average_time_between_aids = dfff.groupby(\n",
    "        'session')['time_diff'].mean().astype('timedelta64[s]')\n",
    "    dfff['mn_time_b/w_aids'] = dfff['session'].map(average_time_between_aids)\n",
    "    dfff['mn_time_b/w_aids'] = dfff['mn_time_b/w_aids'].fillna(0)\n",
    "    dfff['mn_time_b/w_aids'] = round(dfff['mn_time_b/w_aids'],\n",
    "                                     0).astype(np.int32)\n",
    "    dfff.drop(columns=['time_diff'], inplace=True)\n",
    "    chunk = cudf.DataFrame(dfff)\n",
    "\n",
    "    # 'type_counts_ses' Кол-во действий кажд.типа в session\n",
    "    chunk['type_counts_clicks'] = chunk['session'].map(\n",
    "        chunk[chunk['type'] == 0].groupby('session')['aid'].count())\n",
    "    chunk['type_counts_carts'] = chunk['session'].map(\n",
    "        chunk[chunk['type'] == 1].groupby('session')['aid'].count())\n",
    "    chunk['type_counts_orders'] = chunk['session'].map(\n",
    "        chunk[chunk['type'] == 2].groupby('session')['aid'].count())\n",
    "\n",
    "    # freq_per_type' Частота кликов/ картов/ ордеров(кол-во/длина сессии в мин) в session\n",
    "    chunk[\n",
    "        'freq_per_clicks'] = chunk['type_counts_clicks'] / chunk['session_len']\n",
    "    chunk['freq_per_carts'] = chunk['type_counts_carts'] / chunk['session_len']\n",
    "    chunk[\n",
    "        'freq_per_orders'] = chunk['type_counts_orders'] / chunk['session_len']\n",
    "\n",
    "    def ratio_ses_types(series_):\n",
    "        len_ = chunk['session'].map(chunk.groupby('session')['aid'].size())\n",
    "        return series_ / len_\n",
    "\n",
    "    # 'type_ratio_ses' aid clicks/orders/carts ratio в сессии\n",
    "    chunk['ratio_ses_clicks'] = ratio_ses_types(chunk['type_counts_clicks'])\n",
    "    chunk['ratio_ses_carts'] = ratio_ses_types(chunk['type_counts_carts'])\n",
    "    chunk['ratio_ses_orders'] = ratio_ses_types(chunk['type_counts_orders'])\n",
    "\n",
    "    # 'ses_aid_duplic_rate' Были ли в данной сессии повторяющиеся aid, и если да, то сколько раз.\n",
    "    unique_aid_count = chunk.groupby(['session'])['aid'].nunique()\n",
    "    total_aid_count = chunk.groupby(['session'])['aid'].count()\n",
    "    chunk['ses_aid_duplic_rate'] = chunk['session'].map(unique_aid_count /\n",
    "                                                        total_aid_count)\n",
    "\n",
    "    chunk = chunk.drop(columns=['ts', 'type', 'aid'])\n",
    "\n",
    "    dop_ses_fts_df = cudf.concat([dop_ses_fts_df, chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1699455722670,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "UI2uPohjdFE-",
    "outputId": "5170c416-bbb9-4fc5-8a66-c2089069abc7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>session_len</th>\n",
       "      <th>last_aid_type_0</th>\n",
       "      <th>last_aid_type_1</th>\n",
       "      <th>last_aid_type_2</th>\n",
       "      <th>mn_time_b/w_aids</th>\n",
       "      <th>freq_per_clicks</th>\n",
       "      <th>freq_per_carts</th>\n",
       "      <th>freq_per_orders</th>\n",
       "      <th>type_counts_clicks</th>\n",
       "      <th>type_counts_carts</th>\n",
       "      <th>type_counts_orders</th>\n",
       "      <th>ratio_ses_clicks</th>\n",
       "      <th>ratio_ses_carts</th>\n",
       "      <th>ratio_ses_orders</th>\n",
       "      <th>ses_aid_duplic_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899780</td>\n",
       "      <td>1</td>\n",
       "      <td>582732</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899780</td>\n",
       "      <td>1</td>\n",
       "      <td>582732</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899781</td>\n",
       "      <td>944</td>\n",
       "      <td>199008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14155</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899781</td>\n",
       "      <td>944</td>\n",
       "      <td>199008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14155</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899781</td>\n",
       "      <td>944</td>\n",
       "      <td>199008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14155</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907450</th>\n",
       "      <td>14571534</td>\n",
       "      <td>0</td>\n",
       "      <td>272221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>inf</td>\n",
       "      <td>Inf</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907451</th>\n",
       "      <td>14571534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>272221</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>inf</td>\n",
       "      <td>Inf</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907452</th>\n",
       "      <td>14571539</td>\n",
       "      <td>0</td>\n",
       "      <td>317311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907453</th>\n",
       "      <td>14571547</td>\n",
       "      <td>0</td>\n",
       "      <td>1546409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907454</th>\n",
       "      <td>14571548</td>\n",
       "      <td>0</td>\n",
       "      <td>1453906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2907455 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          session  session_len  last_aid_type_0  last_aid_type_1  \\\n",
       "0        12899780            1           582732                0   \n",
       "1        12899780            1           582732                0   \n",
       "2        12899781          944           199008                0   \n",
       "3        12899781          944           199008                0   \n",
       "4        12899781          944           199008                0   \n",
       "...           ...          ...              ...              ...   \n",
       "2907450  14571534            0           272221                0   \n",
       "2907451  14571534            0                0           272221   \n",
       "2907452  14571539            0           317311                0   \n",
       "2907453  14571547            0          1546409                0   \n",
       "2907454  14571548            0          1453906                0   \n",
       "\n",
       "         last_aid_type_2  mn_time_b/w_aids  freq_per_clicks freq_per_carts  \\\n",
       "0                      0                58         2.000000           <NA>   \n",
       "1                      0                58         2.000000           <NA>   \n",
       "2                      0             14155         0.005297           <NA>   \n",
       "3                      0             14155         0.005297           <NA>   \n",
       "4                      0             14155         0.005297           <NA>   \n",
       "...                  ...               ...              ...            ...   \n",
       "2907450                0                 7              inf            Inf   \n",
       "2907451                0                 7              inf            Inf   \n",
       "2907452                0                 0              inf           <NA>   \n",
       "2907453                0                 0              inf           <NA>   \n",
       "2907454                0                 0              inf           <NA>   \n",
       "\n",
       "        freq_per_orders  type_counts_clicks type_counts_carts  \\\n",
       "0                  <NA>                   2              <NA>   \n",
       "1                  <NA>                   2              <NA>   \n",
       "2                  <NA>                   5              <NA>   \n",
       "3                  <NA>                   5              <NA>   \n",
       "4                  <NA>                   5              <NA>   \n",
       "...                 ...                 ...               ...   \n",
       "2907450            <NA>                   1                 1   \n",
       "2907451            <NA>                   1                 1   \n",
       "2907452            <NA>                   1              <NA>   \n",
       "2907453            <NA>                   1              <NA>   \n",
       "2907454            <NA>                   1              <NA>   \n",
       "\n",
       "        type_counts_orders  ratio_ses_clicks ratio_ses_carts ratio_ses_orders  \\\n",
       "0                     <NA>               1.0            <NA>             <NA>   \n",
       "1                     <NA>               1.0            <NA>             <NA>   \n",
       "2                     <NA>               1.0            <NA>             <NA>   \n",
       "3                     <NA>               1.0            <NA>             <NA>   \n",
       "4                     <NA>               1.0            <NA>             <NA>   \n",
       "...                    ...               ...             ...              ...   \n",
       "2907450               <NA>               0.5             0.5             <NA>   \n",
       "2907451               <NA>               0.5             0.5             <NA>   \n",
       "2907452               <NA>               1.0            <NA>             <NA>   \n",
       "2907453               <NA>               1.0            <NA>             <NA>   \n",
       "2907454               <NA>               1.0            <NA>             <NA>   \n",
       "\n",
       "         ses_aid_duplic_rate  \n",
       "0                        1.0  \n",
       "1                        1.0  \n",
       "2                        0.8  \n",
       "3                        0.8  \n",
       "4                        0.8  \n",
       "...                      ...  \n",
       "2907450                  0.5  \n",
       "2907451                  0.5  \n",
       "2907452                  1.0  \n",
       "2907453                  1.0  \n",
       "2907454                  1.0  \n",
       "\n",
       "[2907455 rows x 16 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dop_ses_fts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfJHAs88P9TN"
   },
   "outputs": [],
   "source": [
    "dop_ses_fts_df.to_parquet(f'{main_path}/LB/features/test/dop_user_features.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvTnSgbv-xqB"
   },
   "source": [
    "## признаки Сессии - товары"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiY5sAfqEDWU"
   },
   "source": [
    "**Косинусное расстояние_1/3 часть**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIYl7_9VhHvV"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efm7yoAsiiVE"
   },
   "outputs": [],
   "source": [
    "data_pl = pl.DataFrame({\n",
    "    'session': pl.Series(for_features_df_sessions['session']),\n",
    "    'aid': pl.Series(for_features_df_sessions['aid'])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rE482r9il8N"
   },
   "outputs": [],
   "source": [
    "sentences_df = data_pl.groupby('session').agg(pl.col('aid').alias('sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1152,
     "status": "ok",
     "timestamp": 1699526167794,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "ntpUGS54ioAZ",
    "outputId": "e91f46ec-48d2-48bc-96c9-cfa2c5f8b840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 s, sys: 91.4 ms, total: 1.38 s\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Создание \"предложений\" для каждого пользователя\n",
    "sentences = sentences_df['sentence'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28229,
     "status": "ok",
     "timestamp": 1699526196018,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "eO-Numo7ipqO",
    "outputId": "336fa660-0ed2-49a5-bdf6-330d26565165"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 369 ms, total: 1min 1s\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Обучение модели Word2Vec\n",
    "model = Word2Vec(sentences=sentences, vector_size=32, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21766,
     "status": "ok",
     "timestamp": 1699526220129,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "RC24rWIOivvN",
    "outputId": "ea97b687-e6f7-46cc-ccbf-e6e7a982c497"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "921704it [00:21, 43187.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Вычисление векторных представлений для пользователей\n",
    "user_vectors = {}\n",
    "for row in tqdm(sentences_df.iter_rows()):\n",
    "\n",
    "    session = row[0]\n",
    "    history = row[1]\n",
    "    user_vector = np.mean([model.wv[item] for item in history if item in model.wv], axis=0)\n",
    "    user_vectors[session] = user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwDfvRTHi3OF"
   },
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(session: str, aid: str) -> float:\n",
    "    \"\"\"\n",
    "    Вычисляет косинусное сходство между вектором пользователя и вектором товара.\n",
    "\n",
    "    :param session: Уникальный идентификатор сеанса пользователя.\n",
    "\n",
    "    :param aid: Уникальный идентификатор товара (item).\n",
    "\n",
    "    :return: Косинусное сходство между векторами пользователя и товара.\n",
    "    \"\"\"\n",
    "    # Получаем вектор пользователя из предварительно вычисленных векторов.\n",
    "    user_vector: np.ndarray = user_vectors[session]\n",
    "\n",
    "    # Получаем вектор товара из модели Word2Vec или используем нулевой вектор, если товар отсутствует в модели.\n",
    "    item_vector: np.ndarray = model.wv[aid] if aid in model.wv else np.zeros(model.vector_size)\n",
    "\n",
    "    # Вычисляем косинусное сходство между векторами пользователя и товара.\n",
    "    cosine_sim: float = cosine_similarity([user_vector], [item_vector])[0][0]\n",
    "\n",
    "    return cosine_sim\n",
    "\n",
    "num_groups = data_pl.get_column(\"session\").len()\n",
    "data_pl = data_pl.unique(subset=['session', 'aid'])\n",
    "\n",
    "with tqdm(total=num_groups) as pbar:\n",
    "\n",
    "    data_pl_f = data_pl.with_columns(\n",
    "        pl.struct(['session','aid']) \\\n",
    "          .apply(w_pbar(pbar, lambda x: compute_cosine_similarity(x['session'], x['aid']))).alias('cosine_similarity')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiQrr7oeqI4v"
   },
   "outputs": [],
   "source": [
    "data_pl_f.write_parquet(f'{main_path}/LB/features/test/user_item_features.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xMaXlnAcWDO"
   },
   "source": [
    "# Создание датасета test_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ehr-32HUBWHk"
   },
   "source": [
    "## Создание списка test_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jquDEcrBWHm"
   },
   "outputs": [],
   "source": [
    "cand_n = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93CyBXv2BWHo"
   },
   "outputs": [],
   "source": [
    "test_candidates_sessions = pd.read_parquet(\n",
    "    f'{main_path}/LB/data/test_candidates_sessions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40002,
     "status": "ok",
     "timestamp": 1699534360128,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "vyQCZ3ihBWHo",
    "outputId": "08ac1212-c451-4836-ece5-04c367d7520a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:39<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "covis_matrix = read_covis_to_dict(name='test_covis_matrix', n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GOxykiuVBWHo"
   },
   "outputs": [],
   "source": [
    "top_pop_aids = set(\n",
    "    test_candidates_sessions['aid'].value_counts().index[:cand_n].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CFrLPX1tBWHo"
   },
   "outputs": [],
   "source": [
    "# Преобразование датафрейма в словарь\n",
    "test_dict = test_candidates_sessions.sort_values(\n",
    "    [\"session\", \"ts\"]).groupby('session')['aid'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127675,
     "status": "ok",
     "timestamp": 1699535016112,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "0JhGwsxdBWHp",
    "outputId": "4e762126-12f8-4602-d5bc-c8f2f9f0382f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 921704/921704 [02:03<00:00, 7457.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Словарь с признаком-рангом по ковиз-матрице сохранен в : /content/drive/Othercomputers/Mac/Jup.Notebook/LB/features/test/covis_features.pickle\n"
     ]
    }
   ],
   "source": [
    "# Создание списка самих кандидатов для будушего тест.датасета\n",
    "labels, covis_features = create_labels(n=cand_n,\n",
    "                                       inp_dict=test_dict,\n",
    "                                       covis=covis_matrix,\n",
    "                                       top_pop_aids=top_pop_aids,\n",
    "                                       cov_f=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 678,
     "status": "ok",
     "timestamp": 1699535016778,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "_yMm14oSBWHq",
    "outputId": "65c2172f-53ad-4296-e969-a463d1fe59a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 921704/921704 [00:00<00:00, 2219483.11it/s]\n"
     ]
    }
   ],
   "source": [
    "sessions = []\n",
    "aid_lists = []\n",
    "\n",
    "for session, aids in tqdm(labels.items()):\n",
    "    sessions.append(session)\n",
    "    aid_lists.append(aids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTjvOzK4BWHr"
   },
   "outputs": [],
   "source": [
    "test_candidates_ = pd.DataFrame({'session': sessions, 'labels': aid_lists})\n",
    "test_candidates_['session'] = test_candidates_['session'].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13532,
     "status": "ok",
     "timestamp": 1699535049856,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "KyR5tzoUBWHr",
    "outputId": "1e9e56c3-7848-4767-a8d2-e74a0f14f84a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "part:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 184340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "part:  20%|██        | 1/5 [00:02<00:10,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184340 368680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "part:  40%|████      | 2/5 [00:04<00:07,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368680 553020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "part:  60%|██████    | 3/5 [00:07<00:04,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553020 737360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "part:  80%|████████  | 4/5 [00:10<00:02,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737360 921700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "part: 100%|██████████| 5/5 [00:12<00:00,  2.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# Сохранение списка самих кандидатов для будущего создания тест.датасета\n",
    "folder_path = f'{main_path}/LB/test_candidates'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "partt = len(test_candidates_) // 5\n",
    "\n",
    "for batch in tqdm(range(5), desc='part'):\n",
    "\n",
    "    start = partt * batch\n",
    "    end = partt + start\n",
    "    print(start, end)\n",
    "\n",
    "    if batch == 4:\n",
    "        batch_ = test_candidates_.loc[start:end]\n",
    "    else:\n",
    "        batch_ = test_candidates_.loc[start:end - 1]\n",
    "\n",
    "    batch_ = batch_.explode('labels')\n",
    "\n",
    "    batch_['labels'] = batch_['labels'].astype(np.int32)\n",
    "\n",
    "    batch_.to_parquet(f'{folder_path}/test_candidates_{batch}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkiRyFd_BWHs"
   },
   "outputs": [],
   "source": [
    "del test_candidates_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GW3KG3DABWHs"
   },
   "source": [
    "## Преобразование covis - features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gme4w1gFQ-g"
   },
   "source": [
    "Преобразование pickle признака-ранга по матрице ко-посещений в parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50ZV3gUGBWHs"
   },
   "outputs": [],
   "source": [
    "features_df = (pd.DataFrame.from_dict([\n",
    "    (session_id, aid, rank) for session_id, items in covis_features.items()\n",
    "    for aid, rank in items.items()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvIGDIXdBWHs"
   },
   "outputs": [],
   "source": [
    "features_df.columns = ['session', 'aid', 'rank']\n",
    "features_df['session'] = features_df['session'].astype(np.int32)\n",
    "features_df['aid'] = features_df['aid'].astype(np.int32)\n",
    "features_df['rank'] = features_df['rank'].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2851,
     "status": "ok",
     "timestamp": 1699535182556,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "YJgkuv3cBWHs",
    "outputId": "b52174aa-79cf-4a82-fdb7-d907074d6597"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "part: 100%|██████████| 5/5 [00:02<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_path = f'{main_path}/LB/features/test/covis_features'\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "features_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "partt = len(features_df) // 5\n",
    "\n",
    "for batch in tqdm(range(5), desc='part'):\n",
    "\n",
    "    start = partt * batch\n",
    "    end = partt * (batch + 1)\n",
    "    batch_ = features_df.loc[start:end]\n",
    "\n",
    "    batch_.to_parquet(f'{folder_path}/covis_features_{batch}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eC6OoBMBWHt"
   },
   "source": [
    "## Создание признаков  популярности товара по типам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70C3xOUZBWHt"
   },
   "outputs": [],
   "source": [
    "for_features_df = test_candidates_sessions.drop(columns=['ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 908,
     "status": "ok",
     "timestamp": 1699535363809,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "ITrlBG-aBWHt",
    "outputId": "7afadc59-11c3-485c-b6d5-6b31dbe645d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  4.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Сгруппируем исходный DataFrame по столбцу 'type'\n",
    "grouped = for_features_df.groupby('type')\n",
    "\n",
    "id_2_type = {0: 'clicks', 1: 'carts', 2: 'orders'}\n",
    "\n",
    "# Пройдемся по каждой группе и выполним ранжирование aid по встречаемости\n",
    "for name, group in tqdm(grouped):\n",
    "    # Считаем количество вхождений каждого aid в текущей группе и создадим временный DataFrame\n",
    "    aid_counts = group['aid'].value_counts().reset_index()\n",
    "    aid_counts.columns = ['aid', 'count']\n",
    "\n",
    "    # Добавим столбец с рангом, используя функцию rank()\n",
    "    aid_counts['rank_pops'] = aid_counts['count'].rank(ascending=False,\n",
    "                                                       method='dense')\n",
    "    aid_counts.drop(columns=['count'], inplace=True)\n",
    "\n",
    "    # Присоединим результат к исходной группе и добавим в общий результатный DataFrame\n",
    "    group = group.drop(columns=['session', 'type']).drop_duplicates(\n",
    "        subset=['aid'])\n",
    "    merged_group = pd.merge(group, aid_counts, on='aid', how='left')\n",
    "    merged_group.fillna(-1, inplace=True)\n",
    "    merged_group['rank_pops'] = merged_group['rank_pops'].astype(np.int32)\n",
    "    merged_group.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    merged_group.to_parquet(\n",
    "        f'{main_path}/LB/features/test/pop_features_{id_2_type[name]}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Guf6b-SCBWHt"
   },
   "source": [
    "## Добавление признаков к test_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AT9Z418nBWHu"
   },
   "outputs": [],
   "source": [
    "base_item_features = pd.read_parquet(\n",
    "    f'{main_path}/LB/features/test/base_item_features.parquet')\n",
    "base_user_features = pd.read_parquet(\n",
    "    f'{main_path}/LB/features/test/base_user_features.parquet')\n",
    "dop_user_features = pd.read_parquet(\n",
    "    f'{main_path}/LB/features/test/dop_user_features.parquet')\n",
    "dop_item_featues = pd.read_parquet(\n",
    "    f'{main_path}/LB/features/test/dop_item_features.parquet')\n",
    "user_item_features = pd.read_parquet(\n",
    "    f'{main_path}/LB/features/test/user_item_features.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsQt9Og9J3cV"
   },
   "outputs": [],
   "source": [
    "# Список файлов Parquet\n",
    "file_list = glob.glob(f'{main_path}/LB/test_candidates/*')\n",
    "file_list_covis_f = glob.glob(f'{main_path}/LB/features/test/covis_features/*')\n",
    "file_list_pops = glob.glob(f'{main_path}/LB/features/test/pop_features_*.parquet')\n",
    "\n",
    "file_list.sort()\n",
    "file_list_covis_f.sort()\n",
    "file_list_pops.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 347427,
     "status": "ok",
     "timestamp": 1699536676749,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "qIXdgMSIJ6qk",
    "outputId": "657c4a40-d128-4a0c-9666-047e4b56000c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "parts: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0_types: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0_types: 1it [00:14, 14.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0_types: 2it [00:29, 14.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0_types: 3it [00:44, 14.80s/it]\n",
      "parts: 1it [01:10, 70.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1_types: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1_types: 1it [00:14, 14.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1_types: 2it [00:29, 14.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1_types: 3it [00:44, 14.69s/it]\n",
      "parts: 2it [02:18, 69.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2_types: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2_types: 1it [00:14, 14.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2_types: 2it [00:29, 14.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2_types: 3it [00:44, 14.69s/it]\n",
      "parts: 3it [03:28, 69.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3_types: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3_types: 1it [00:14, 14.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3_types: 2it [00:29, 14.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3_types: 3it [00:44, 14.79s/it]\n",
      "parts: 4it [04:37, 69.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4_types: 0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4_types: 1it [00:14, 14.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4_types: 2it [00:29, 14.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 2/5\n",
      "Done 3/5\n",
      "Done 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "4_types: 3it [00:44, 14.82s/it]\n",
      "parts: 5it [05:47, 69.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# Цикл для чтения и объединения файлов\n",
    "for iter_numb, (file,\n",
    "                file_2) in tqdm(enumerate(zip(file_list, file_list_covis_f)),\n",
    "                                desc=f'parts'):\n",
    "\n",
    "    # Чтение файла Parquet во временный DataFrame\n",
    "    df_ = pd.read_parquet(file)\n",
    "    covis_f = pd.read_parquet(file_2)\n",
    "\n",
    "    df_ = df_.rename(columns={'labels': 'aid'})\n",
    "    # Базовые user, item features\n",
    "    df_ = df_.merge(base_item_features, on=['aid'], how='left').fillna(-1)\n",
    "    df_ = df_.merge(base_user_features, on=['session'], how='left').fillna(-1)\n",
    "    # User-item features\n",
    "    df_ = df_.merge(user_item_features, on=['session', 'aid'],\n",
    "                    how='left').fillna(-1)\n",
    "    # Доп. user features\n",
    "    df_ = df_.merge(dop_user_features[[\n",
    "        'session', 'session_len', 'mean_time_bw_aids', 'ses_aid_duplic_rate'\n",
    "    ]],\n",
    "                    on=['session'],\n",
    "                    how='left').fillna(-1)\n",
    "    df_ = df_.merge(covis_f, on=['session', 'aid'], how='left').fillna(-1)\n",
    "    #Доп. item features\n",
    "    df_ = df_.merge(dop_item_featues, on=['aid'], how='left').fillna(-1)\n",
    "    print('Done 1/3')\n",
    "\n",
    "    for (type_, file_path_, index) in tqdm(\n",
    "        (zip(['carts', 'clicks', 'orders'], file_list_pops, [1, 0, 2])),\n",
    "            desc=f'{iter_numb}_types'):\n",
    "\n",
    "        # Доп. item features - по type\n",
    "        columns_ = ['aid', 'rank_pops']\n",
    "        pop_features = pd.read_parquet(file_path_)\n",
    "        df_m = df_.merge(pop_features[columns_], on=['aid'],\n",
    "                         how='left').fillna(-1)\n",
    "        print('Done 2/5')\n",
    "        #Доп. user features - по type\n",
    "        df_m = df_m.merge(\n",
    "            dop_user_features[['session', f'last_aid_type_{index}']],\n",
    "            on=['session'],\n",
    "            how='left').fillna(-1)\n",
    "        print('Done 3/5')\n",
    "        columns_user_item = [\n",
    "            'session', f'freq_per_{type_}', f'ratio_ses_{type_}',\n",
    "            f'type_counts_{type_}'\n",
    "        ]\n",
    "        df_m = df_m.merge(dop_user_features[columns_user_item],\n",
    "                          on=['session'],\n",
    "                          how='left').fillna(-1)\n",
    "        print('Done 4/5')\n",
    "\n",
    "        folder_path = f'{main_path}/LB/test_candidates_{type_}'\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        df_m.to_parquet(\n",
    "            f\"{folder_path}/test_candidates_{type_}_{iter_numb}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t46HjRCXMAOm"
   },
   "source": [
    "# Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17364,
     "status": "ok",
     "timestamp": 1699591066630,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "rb_nas-mm3oH",
    "outputId": "6d52ea38-1a2f-4c71-cd9a-0071bbd8bc90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.3)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdxUlNpYm3oH"
   },
   "outputs": [],
   "source": [
    "import catboost\n",
    "from catboost import CatBoostRanker, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zi4a2nQAm3oH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CATBOOST_GPU'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6H1pl8IxXJ-z"
   },
   "outputs": [],
   "source": [
    "params_name = 'catb_tun'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxYMJKLAyYD_"
   },
   "source": [
    "**Предсказание на тесте**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 594991,
     "status": "ok",
     "timestamp": 1699539592391,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "rsuoU5mLBWHv",
    "outputId": "95354817-cf79-4401-94cb-fbd550ebb02b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "type:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:01<00:04,  1.24s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:03<00:05,  1.71s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:05<00:04,  2.01s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:08<00:02,  2.31s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.31s/it]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:24<01:39, 24.89s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:49<01:13, 24.59s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [01:13<00:48, 24.40s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [01:37<00:24, 24.37s/it]\u001b[A\n",
      "100%|██████████| 5/5 [02:02<00:00, 24.46s/it]\n",
      "type:  33%|███▎      | 1/3 [03:30<07:00, 210.22s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:03<00:12,  3.20s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:07<00:10,  3.66s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:11<00:07,  3.95s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:16<00:04,  4.40s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:22<00:00,  4.42s/it]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:16<01:07, 16.95s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:33<00:50, 16.73s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:49<00:33, 16.58s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [01:06<00:16, 16.68s/it]\u001b[A\n",
      "100%|██████████| 5/5 [01:23<00:00, 16.74s/it]\n",
      "type:  67%|██████▋   | 2/3 [06:21<03:07, 187.48s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:03<00:12,  3.24s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:07<00:11,  3.76s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:11<00:08,  4.01s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:17<00:04,  4.60s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:22<00:00,  4.57s/it]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:24<01:38, 24.66s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:49<01:13, 24.56s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [01:13<00:49, 24.67s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [01:39<00:24, 24.88s/it]\u001b[A\n",
      "100%|██████████| 5/5 [02:05<00:00, 25.09s/it]\n",
      "type: 100%|██████████| 3/3 [09:54<00:00, 198.00s/it]\n"
     ]
    }
   ],
   "source": [
    "test_predictions_full = pd.DataFrame()\n",
    "\n",
    "# Прохождение по каждому типу кандидатов\n",
    "for typee in tqdm(['clicks', 'carts', 'orders'], desc='type'):\n",
    "\n",
    "    path = f\"{main_path}/LB/test_candidates_{typee}/*\"\n",
    "    test_candidates = read_parquets(path)\n",
    "    test_candidates = test_candidates.sort_values('session')\n",
    "    test_candidates = test_candidates.reset_index(drop=True)\n",
    "\n",
    "    # Подготовка частей данных для предсказания\n",
    "    FEATURES = test_candidates.columns[2:]\n",
    "    dtest = Pool(data=test_candidates[FEATURES])\n",
    "    preds = np.zeros(len(test_candidates))\n",
    "\n",
    "    # Предсказание и его усреднение по 5 фолдам\n",
    "    for fold in tqdm(range(5)):\n",
    "        model = CatBoostRanker(random_state=42)\n",
    "        model.load_model(\n",
    "            f'{main_path}/models/{params_name}/{params_name}_{fold}_{typee}')\n",
    "        fold_preds = model.predict(dtest)\n",
    "        preds += fold_preds / 5\n",
    "\n",
    "    # Отбор топ-20 предсказаний для сессии и доп трансформация\n",
    "    lv_predictions = test_candidates[['session', 'aid']].copy()\n",
    "    lv_predictions['pred'] = preds\n",
    "    lv_predictions = lv_predictions.sort_values(\n",
    "        ['session', 'pred'], ascending=[True, False]).reset_index(drop=True)\n",
    "    lv_predictions['n'] = lv_predictions.groupby(\n",
    "        'session').aid.cumcount().astype('int8')\n",
    "    lv_predictions = lv_predictions.loc[lv_predictions.n < 20]\n",
    "    lv_predictions = lv_predictions.groupby('session').aid.apply(list)\n",
    "    lv_predictions = lv_predictions.to_frame().reset_index()\n",
    "    lv_predictions.rename(columns={'aid': 'labels'}, inplace=True)\n",
    "    lv_predictions['type'] = typee\n",
    "\n",
    "    # Объединение временного DataFrame с основным датасетом\n",
    "    test_predictions_full = pd.concat([test_predictions_full, lv_predictions],\n",
    "                                      ignore_index=True)\n",
    "    del lv_predictions, preds, test_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltOGQf9jyhVh"
   },
   "source": [
    "**Предсказание на трейне** \\\n",
    "Получаю предсказания на тренировочном датасете  \n",
    " кандидатов, на котором обучалась модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180318,
     "status": "ok",
     "timestamp": 1699591428218,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "8fOE7m3yym5R",
    "outputId": "d68b26ff-cf1f-4c13-849a-f0232fff3e62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "type:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:05<00:21,  5.35s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:09<00:14,  4.81s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:14<00:09,  4.63s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:18<00:04,  4.40s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:22<00:00,  4.54s/it]\n",
      "type:  33%|███▎      | 1/3 [01:11<02:22, 71.47s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:02<00:08,  2.23s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:04<00:07,  2.36s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:06<00:04,  2.33s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:09<00:02,  2.39s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:11<00:00,  2.38s/it]\n",
      "type:  67%|██████▋   | 2/3 [02:02<00:59, 59.30s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:03<00:14,  3.66s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:06<00:10,  3.34s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:10<00:06,  3.31s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:13<00:03,  3.30s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:16<00:00,  3.35s/it]\n",
      "type: 100%|██████████| 3/3 [02:59<00:00, 59.90s/it]\n"
     ]
    }
   ],
   "source": [
    "train_predictions_full = pd.DataFrame()\n",
    "\n",
    "# Прохождение по каждому типу кандидатов\n",
    "for typee in tqdm(['clicks', 'carts', 'orders'], desc='type'):\n",
    "\n",
    "    path = f\"{main_path}/tr/ver_6/tr_candidates_{typee}/*\"\n",
    "    train_candidates = read_parquets(path)\n",
    "    train_candidates = train_candidates.sort_values('session')\n",
    "    train_candidates = train_candidates.reset_index(drop=True)\n",
    "\n",
    "    # Подготовка частей данных для предсказания\n",
    "    FEATURES = train_candidates.columns[2:-1]\n",
    "    dtest = Pool(data=train_candidates[FEATURES])\n",
    "    preds = np.zeros(len(train_candidates))\n",
    "\n",
    "    # Предсказание и его усреднение по 5 фолдам\n",
    "    for fold in tqdm(range(5)):\n",
    "        model = CatBoostRanker(random_state=42)\n",
    "        model.load_model(\n",
    "            f'{main_path}/models/{params_name}/{params_name}_{fold}_{typee}')\n",
    "        fold_preds = model.predict(dtest)\n",
    "        preds += fold_preds / 5\n",
    "\n",
    "    # Отбор топ-20 предсказаний для сессии и доп трансформация\n",
    "    lv_predictions = train_candidates[['session', 'aid']].copy()\n",
    "    lv_predictions['pred'] = preds\n",
    "    lv_predictions = lv_predictions.sort_values(\n",
    "        ['session', 'pred'], ascending=[True, False]).reset_index(drop=True)\n",
    "    lv_predictions['n'] = lv_predictions.groupby(\n",
    "        'session').aid.cumcount().astype('int8')\n",
    "    lv_predictions = lv_predictions.loc[lv_predictions.n < 20]\n",
    "    lv_predictions = lv_predictions.groupby('session').aid.apply(list)\n",
    "    lv_predictions = lv_predictions.to_frame().reset_index()\n",
    "    lv_predictions.rename(columns={'aid': 'labels'}, inplace=True)\n",
    "    lv_predictions['type'] = typee\n",
    "\n",
    "    # Объединение временного DataFrame с основным датасетом\n",
    "    train_predictions_full = pd.concat(\n",
    "        [train_predictions_full, lv_predictions], ignore_index=True)\n",
    "    del lv_predictions, preds, train_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWaiATuKMAOn"
   },
   "source": [
    "# Оценка метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xpz8UAmhx7tl"
   },
   "source": [
    "**На тесте**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ffa7872"
   },
   "outputs": [],
   "source": [
    "id2type_name = 'id2type.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7742d86f"
   },
   "outputs": [],
   "source": [
    "test_labels = pd.read_parquet(f'{main_path}/LB/data/test_labels.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d15538e9"
   },
   "outputs": [],
   "source": [
    "with open(f'{main_path}/pkl/{id2type_name}', 'rb') as file:\n",
    "    id2type = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60763,
     "status": "ok",
     "timestamp": 1699539689372,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "7fcdfa6d",
    "outputId": "f94682f9-fad4-42df-b332-1fe81c4e733a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score : 0.5281948462262794\n"
     ]
    }
   ],
   "source": [
    "print('Model score :', metric_eval(test_predictions_full, test_labels,\n",
    "                                   id2type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWEqC24nx-01"
   },
   "source": [
    "**На трейне**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlH0UocF8zUm"
   },
   "outputs": [],
   "source": [
    "# train_predictions_full.to_parquet(f'{main_path}/LB/train_predictions_full.parquet')\n",
    "# train_predictions_full = pd.read_parquet(f'{main_path}/LB/train_predictions_full.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qETrXSzqx7M8"
   },
   "outputs": [],
   "source": [
    "# В роли test_labels испольую таргеты, созданные для обучения на этом тренировочном\n",
    "# датасете (на котором я выше предсказался)\n",
    "test_labels = pd.read_parquet(f'{main_path}/s/targets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1699603014488,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "wLbKadvIOi8H",
    "outputId": "2c4dd13d-7594-4835-f40b-2f5134bc349e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score : 0.52907483652647848\n"
     ]
    }
   ],
   "source": [
    "print('Model score :', metric_eval(train_predictions_full, test_labels,\n",
    "                                   id2type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1699603177517,
     "user": {
      "displayName": "Stas Krupnov",
      "userId": "12188064098878037970"
     },
     "user_tz": -420
    },
    "id": "FJjIjHi2PRr7",
    "outputId": "34909510-3002-47e1-f7c7-4126b824d6db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1666033484586558 %\n"
     ]
    }
   ],
   "source": [
    "print(abs(0.52907483652647848 - 0.5281948462262794)/0.5281948462262794*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHDaqb3-PnnC"
   },
   "source": [
    "**Модель не переобучилась, разница в метрике между трейн и тест = 0.16%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я проверил производительность обученной ранее модели на отложенном оригинальном тестовом  \n",
    "датасете test_main\n",
    "- метрика получилась схожей с метрикой, полученной на тестовой части, взятой из   \n",
    "послед.недели train_main  \n",
    "- переобучения не обнаружилось"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "fda2ef49"
   ],
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287.205872px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
